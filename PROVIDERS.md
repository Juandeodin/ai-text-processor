# ü§ñ AI Text Processor - Configuraci√≥n Multi-Proveedor

## Configuraci√≥n R√°pida por Proveedor

### OpenAI (Recomendado para principiantes)
```env
AI_PROVIDER=openai
OPENAI_API_KEY=sk-...
```
**Ventajas**: F√°cil configuraci√≥n, excelente calidad, documentaci√≥n extensa
**Costo**: ~$0.002/1K tokens (GPT-3.5)

### Anthropic Claude (Mejor para textos largos)
```env
AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
```
**Ventajas**: Excelente con contextos largos, muy seguro, buena en espa√±ol
**Costo**: ~$0.008/1K tokens (Claude Haiku)

### Google Gemini (M√°s r√°pido)
```env
AI_PROVIDER=google
GOOGLE_AI_API_KEY=AI...
```
**Ventajas**: Muy r√°pido, multimodal, bien optimizado para traducci√≥n
**Costo**: Gratis hasta 60 requests/minuto

### Azure OpenAI (Para empresas)
```env
AI_PROVIDER=azure
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://tu-recurso.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo
```
**Ventajas**: Cumplimiento empresarial, SLA garantizado, ubicaci√≥n de datos
**Costo**: Similar a OpenAI con facturaci√≥n empresarial

### Hugging Face (Econ√≥mico)
```env
AI_PROVIDER=huggingface
HUGGINGFACE_API_KEY=hf_...
HUGGINGFACE_MODEL=meta-llama/Llama-2-70b-chat-hf
```
**Ventajas**: Muy econ√≥mico, muchos modelos disponibles, open source
**Costo**: ~$0.0008/1K tokens

### Local con Ollama (Gratuito y privado)
```env
AI_PROVIDER=local
LOCAL_LLM_ENDPOINT=http://localhost:11434
LOCAL_LLM_MODEL=llama2
```
**Ventajas**: Completamente gratuito, total privacidad, sin l√≠mites de uso
**Requerimientos**: 8GB+ RAM, GPU recomendada

## Instalaci√≥n por Pasos

### 1. Configuraci√≥n B√°sica
```bash
git clone <repo-url>
cd ai-text-processor
npm install
npm run setup  # Script autom√°tico de configuraci√≥n
```

### 2. Para Ollama (LLM Local)
```bash
# Windows
winget install Ollama.Ollama

# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar modelo
ollama pull llama2
ollama pull mistral
```

### 3. Modelos Recomendados por Caso de Uso

#### Transcripci√≥n (correcci√≥n de texto)
- **OpenAI**: `gpt-3.5-turbo` (r√°pido y econ√≥mico)
- **Anthropic**: `claude-3-haiku-20240307` (mejor contexto)
- **Local**: `llama2` o `mistral`

#### Traducci√≥n
- **Google**: `gemini-pro` (especializado en idiomas)
- **OpenAI**: `gpt-4` (mejor calidad)
- **Anthropic**: `claude-3-sonnet-20240229` (balance calidad/precio)

#### Uso masivo/empresarial
- **Azure**: `gpt-35-turbo` (SLA empresarial)
- **Hugging Face**: `meta-llama/Llama-2-70b-chat-hf` (econ√≥mico)
- **Local**: Cualquier modelo compatible

## Troubleshooting

### Error: "Provider not configured"
Verifica que tengas todas las variables necesarias en `.env`

### Error: "API key invalid" 
Revisa que tu API key sea v√°lida y tenga cr√©ditos

### Error: "Model not found" (Hugging Face)
Algunos modelos pueden estar en cola. Usa modelos alternativos:
- `microsoft/DialoGPT-large`
- `google/flan-t5-large`

### Error: "Connection refused" (Local)
Aseg√∫rate de que Ollama est√© ejecut√°ndose:
```bash
ollama serve
```

### Performance lento
- **OpenAI/Anthropic**: Considera usar modelos m√°s peque√±os
- **Local**: Usa GPU si est√° disponible
- **Hugging Face**: Algunos modelos tienen cold start

## Scripts √ötiles

### Cambiar proveedor r√°pidamente
```bash
# Cambiar a Claude
echo "AI_PROVIDER=anthropic" >> .env

# Cambiar a Gemini  
echo "AI_PROVIDER=google" >> .env

# Reinstalar dependencias del nuevo proveedor
npm run setup
```

### Test de conectividad
```bash
# Crear script de test
node -e "
const { processText } = require('./services/aiService');
processText('Hola mundo', 'transcribe', 'es')
  .then(result => console.log('‚úÖ Funciona:', result))
  .catch(err => console.log('‚ùå Error:', err.message));
"
```

¬°Con esta configuraci√≥n puedes usar cualquier proveedor de IA que necesites! üöÄ
# AI Text Processor ğŸ¤–

Una aplicaciÃ³n web potente para transcribir y traducir textos largos usando Inteligencia Artificial. La aplicaciÃ³n maneja automÃ¡ticamente los lÃ­mites de texto de la IA dividiendo documentos extensos en fragmentos y procesÃ¡ndolos secuencialmente.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Node.js](https://img.shields.io/badge/node.js-v16+-green.svg)
![Express](https://img.shields.io/badge/express-v4.18+-orange.svg)

## ğŸš€ CaracterÃ­sticas

- **Procesamiento de textos largos**: Divide automÃ¡ticamente textos extensos en fragmentos manejables
- **TranscripciÃ³n inteligente**: Mejora ortografÃ­a, puntuaciÃ³n y formato de textos
- **TraducciÃ³n multiidioma**: Traduce a mÃ¡s de 10 idiomas diferentes
- **MÃºltiples proveedores de IA**: Soporte para OpenAI, Anthropic, Google, Azure, Hugging Face y LLMs locales
- **Interfaz moderna**: UI responsive y intuitiva con progreso en tiempo real
- **Streaming en tiempo real**: Muestra resultados parciales mientras procesa
- **Carga de archivos**: Soporte para archivos de texto (.txt)
- **Descarga de resultados**: Exporta los resultados procesados

## ğŸ¤– Proveedores de IA Soportados

| Proveedor | Modelos | ConfiguraciÃ³n Requerida |
|-----------|---------|------------------------|
| **OpenAI** | GPT-3.5, GPT-4 | `OPENAI_API_KEY` |
| **Anthropic** | Claude 3 Haiku, Sonnet, Opus | `ANTHROPIC_API_KEY` |
| **Google** | Gemini Pro, Ultra | `GOOGLE_AI_API_KEY` |
| **Azure OpenAI** | GPT-3.5, GPT-4 | `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` |
| **Hugging Face** | Llama 2, CodeLlama, etc. | `HUGGINGFACE_API_KEY` |
| **Local (Ollama)** | Llama 2, Mistral, etc. | `LOCAL_LLM_ENDPOINT` |

## ğŸ› ï¸ TecnologÃ­as

- **Backend**: Node.js, Express.js
- **Frontend**: HTML5, CSS3, JavaScript (ES6+)
- **IA**: MÃºltiples proveedores (OpenAI, Anthropic, Google, etc.)
- **Streaming**: Server-Sent Events (SSE)

## ğŸ“¦ InstalaciÃ³n

### Requisitos previos
- Node.js v16 o superior
- NPM o Yarn
- API key del proveedor de IA que elijas

### InstalaciÃ³n RÃ¡pida

1. **Clona el repositorio**
```bash
git clone <tu-repositorio-url>
cd ai-text-processor
```

2. **Instala las dependencias base**
```bash
npm install
```

3. **Configura tu proveedor de IA**
```bash
npm run setup
```
Este comando:
- Crea el archivo `.env` automÃ¡ticamente
- Instala las dependencias especÃ­ficas del proveedor
- Te muestra las instrucciones de configuraciÃ³n

4. **Configura las variables de entorno**
Edita el archivo `.env` y configura tu proveedor:

```env
# Selecciona tu proveedor
AI_PROVIDER=openai  # openai, anthropic, google, azure, huggingface, local

# Para OpenAI
OPENAI_API_KEY=tu_clave_api_de_openai_aqui

# Para Anthropic
ANTHROPIC_API_KEY=tu_clave_api_de_anthropic_aqui

# Para Google
GOOGLE_AI_API_KEY=tu_clave_api_de_google_aqui

# Para Azure OpenAI
AZURE_OPENAI_API_KEY=tu_clave_azure_openai_aqui
AZURE_OPENAI_ENDPOINT=https://tu-recurso.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo

# Para Hugging Face
HUGGINGFACE_API_KEY=tu_clave_huggingface_aqui
HUGGINGFACE_MODEL=meta-llama/Llama-2-70b-chat-hf

# Para LLM Local (Ollama)
LOCAL_LLM_ENDPOINT=http://localhost:11434
LOCAL_LLM_MODEL=llama2
```

5. **Inicia la aplicaciÃ³n**
```bash
# Modo desarrollo (con recarga automÃ¡tica)
npm run dev

# Modo producciÃ³n
npm start
```

6. **Abre tu navegador**
Visita `http://localhost:3000`

## ğŸ”§ ConfiguraciÃ³n

### Variables de entorno

| Variable | DescripciÃ³n | Valor por defecto |
|----------|-------------|-------------------|
| `OPENAI_API_KEY` | Tu clave API de OpenAI | Requerido |
| `PORT` | Puerto del servidor | 3000 |
| `MAX_CHUNK_SIZE` | TamaÃ±o mÃ¡ximo de cada fragmento | 3000 |
| `OVERLAP_SIZE` | SuperposiciÃ³n entre fragmentos | 200 |

### ğŸ”‘ Obtener API Keys

#### OpenAI
1. Ve a [OpenAI Platform](https://platform.openai.com/)
2. Inicia sesiÃ³n o crea una cuenta
3. Navega a "API Keys" 
4. Crea una nueva clave API
5. Copia y agrega: `OPENAI_API_KEY=tu_clave_aqui`

#### Anthropic Claude
1. Ve a [Anthropic Console](https://console.anthropic.com/)
2. Crea una cuenta y verifica tu telÃ©fono
3. Ve a "API Keys"
4. Crea una nueva clave
5. Copia y agrega: `ANTHROPIC_API_KEY=tu_clave_aqui`

#### Google AI (Gemini)
1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Inicia sesiÃ³n con tu cuenta de Google
3. Crea una nueva API key
4. Copia y agrega: `GOOGLE_AI_API_KEY=tu_clave_aqui`

#### Hugging Face
1. Ve a [Hugging Face](https://huggingface.co/settings/tokens)
2. Inicia sesiÃ³n en tu cuenta
3. Crea un nuevo token de acceso
4. Copia y agrega: `HUGGINGFACE_API_KEY=tu_clave_aqui`

#### LLM Local (Ollama)
1. Instala [Ollama](https://ollama.ai/)
2. Ejecuta: `ollama pull llama2` (o el modelo que prefieras)
3. Configura: `LOCAL_LLM_ENDPOINT=http://localhost:11434`

## ğŸ“– Uso

### TranscripciÃ³n de texto
1. Selecciona "Transcribir y Corregir" en el menÃº de operaciones
2. Pega o escribe el texto que deseas mejorar
3. Haz clic en "Procesar Texto"
4. Observa el progreso en tiempo real
5. Copia o descarga el resultado

### TraducciÃ³n de texto
1. Selecciona "Traducir" en el menÃº de operaciones
2. Elige el idioma destino
3. Pega el texto a traducir
4. Haz clic en "Procesar Texto"
5. El sistema dividirÃ¡ y traducirÃ¡ automÃ¡ticamente

### Carga de archivos
1. Haz clic en "Cargar Archivo"
2. Selecciona un archivo de texto (.txt)
3. El contenido se cargarÃ¡ automÃ¡ticamente
4. Procede con la transcripciÃ³n o traducciÃ³n

## ğŸ”„ API Endpoints

### POST `/api/text/process`
Procesa texto largo con streaming de respuesta.

**Request Body:**
```json
{
  "text": "Texto a procesar...",
  "operation": "transcribe" | "translate",
  "targetLanguage": "es",
  "options": {
    "maxChunkSize": 3000,
    "model": "gpt-3.5-turbo"
  }
}
```

**Response:** Server-Sent Events con los siguientes tipos:
- `progress`: Progreso del procesamiento
- `chunk_complete`: Chunk individual completado
- `complete`: Procesamiento total completado
- `error`: Error durante el procesamiento

### GET `/api/text/info`
Obtiene informaciÃ³n del servicio.

**Response:**
```json
{
  "service": "AI Text Processor",
  "version": "1.0.0",
  "operations": ["transcribe", "translate"],
  "maxChunkSize": 3000,
  "supportedLanguages": ["es", "en", "fr", ...]
}
```

## ğŸ” ComparaciÃ³n de Proveedores

### ğŸ’° **Costos y Velocidad**
- **OpenAI**: RÃ¡pido, costo moderado, muy buena calidad
- **Anthropic**: Excelente calidad, un poco mÃ¡s caro
- **Google**: Muy rÃ¡pido, competitivo en precio
- **Azure**: IntegraciÃ³n empresarial, precios por volumen
- **Hugging Face**: EconÃ³mico, modelos especializados
- **Local (Ollama)**: Gratuito, privacidad total, requiere hardware

### ğŸ¯ **Casos de Uso Recomendados**
- **TranscripciÃ³n**: OpenAI GPT-4, Google Gemini
- **TraducciÃ³n**: Anthropic Claude, Google Gemini  
- **Uso masivo**: Hugging Face, Local
- **Empresarial**: Azure OpenAI
- **Privacidad**: Local (Ollama)

### ğŸ”„ **Cambiar de Proveedor**
Simplemente cambia `AI_PROVIDER` en tu `.env`:
```env
AI_PROVIDER=anthropic  # Cambiar a Claude
AI_PROVIDER=google     # Cambiar a Gemini
AI_PROVIDER=local      # Cambiar a LLM local
```

## ğŸŒ Idiomas soportados

- ğŸ‡ªğŸ‡¸ EspaÃ±ol
- ğŸ‡ºğŸ‡¸ InglÃ©s
- ğŸ‡«ğŸ‡· FrancÃ©s
- ğŸ‡©ğŸ‡ª AlemÃ¡n
- ğŸ‡®ğŸ‡¹ Italiano
- ğŸ‡µğŸ‡¹ PortuguÃ©s
- ğŸ‡·ğŸ‡º Ruso
- ğŸ‡¯ğŸ‡µ JaponÃ©s
- ğŸ‡°ğŸ‡· Coreano
- ğŸ‡¨ğŸ‡³ Chino
- ğŸ‡¸ğŸ‡¦ Ãrabe
- Y mÃ¡s...

## ğŸ§ª Modo Demo

La aplicaciÃ³n incluye un modo demo que funciona sin clave API para pruebas:

```env
# Para usar modo demo, no configures OPENAI_API_KEY o usa:
OPENAI_API_KEY=demo-key
```

## ğŸ“± CaracterÃ­sticas tÃ©cnicas

### FragmentaciÃ³n inteligente
- DivisiÃ³n por pÃ¡rrafos cuando es posible
- SuperposiciÃ³n entre fragmentos para mantener contexto
- Respeto de lÃ­mites naturales (puntos, espacios)
- ValidaciÃ³n de lÃ­mites de tokens

### Streaming en tiempo real
- Server-Sent Events para updates instantÃ¡neos
- Progreso visual detallado
- Resultados parciales en tiempo real
- Manejo robusto de errores

### Interfaz responsiva
- DiseÃ±o adaptable para mÃ³vil y desktop
- Animaciones suaves y feedback visual
- Carga de archivos drag-and-drop
- Copiar al portapapeles con un clic

## ğŸš€ Despliegue

### Despliegue local
```bash
npm start
```

### Despliegue en producciÃ³n
1. Configura las variables de entorno en tu servidor
2. Ejecuta `npm install --production`
3. Inicia con `npm start` o un process manager como PM2

### Docker (opcional)
```dockerfile
FROM node:16-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3000
CMD ["npm", "start"]
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ› Reporte de errores

Si encuentras algÃºn error, por favor:

1. Verifica que no haya sido reportado anteriormente
2. Incluye pasos para reproducir el error
3. Agrega logs de error si estÃ¡n disponibles
4. Especifica tu entorno (OS, Node.js version, etc.)

## ğŸ“ Soporte

- ğŸ“§ Email: juancas9999@gmail.com


â­ **Â¡Si este proyecto te resulta Ãºtil, no olvides darle una estrella!** â­